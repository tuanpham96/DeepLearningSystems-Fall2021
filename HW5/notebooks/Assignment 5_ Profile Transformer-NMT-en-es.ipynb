{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 5: Profile Transformer-NMT-en-es.ipynb","provenance":[{"file_id":"16JmM4d_Wc3Eh1-iyjkA5_kw8qLDDFhr2","timestamp":1602519669782},{"file_id":"1i4a26jVRVsAIfAGCe5pnl4l51B6GvjWs","timestamp":1595454386969},{"file_id":"17dOcF-VlAVBY0vzgqaANGQ4taSNc2Wp6","timestamp":1571411676663}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UwqhzXA3184z"},"source":["In this assignment, we will first learn to use tensorflow profiler on a toy MNIST model. Then move on to profile the Transformer model used in our Spanish-English Neural Machine Translator (assignment-3). \n","\n","Necessary model modification needs to be made to `Transformer` class to enable `.fit()` method."]},{"cell_type":"markdown","metadata":{"id":"2z9y_24G3Fb3"},"source":["# Profile Model Performance Tutorial\n","\n","Adapted from https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras\n","\n","Machine learning algorithms are typically computationally expensive. It is thus vital to quantify the performance of your machine learning application to ensure that you are running the most optimized version of your model. Use the TensorFlow Profiler to profile the execution of your TensorFlow code."]},{"cell_type":"markdown","metadata":{"id":"9nndORtw6YZI"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"PGaKnRcp3ukE"},"source":["!pip install -U tensorboard_plugin_profile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sSTJAB243pQV"},"source":["from datetime import datetime\n","from packaging import version\n","\n","import os\n","import tensorflow as tf\n","\n","print(\"TensorFlow version: \", tf.__version__)\n","\n","# make sure we are using GPU\n","device_name = tf.test.gpu_device_name()\n","if not device_name:\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ZPy40tR39C1"},"source":["## Train an image classification model with TensorBoard callbacks\n","\n","Tensorflow Profiler works as \"Tensorboard callback\", which requires the `.fit()` method from Keras model interface. \n","\n","Here we use MNIST for quick demonstration purpose."]},{"cell_type":"code","metadata":{"id":"Pm_s4k9t4a8D"},"source":["import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","(ds_train, ds_test), ds_info = tfds.load(\n","    'mnist',\n","    split=['train', 'test'],\n","    shuffle_files=True,\n","    as_supervised=True,\n","    with_info=True,\n",")\n","\n","def normalize_img(image, label):\n","  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n","  return tf.cast(image, tf.float32) / 255., label\n","\n","ds_train = ds_train.map(normalize_img)\n","ds_train = ds_train.batch(128)\n","ds_test = ds_test.map(normalize_img)\n","ds_test = ds_test.batch(128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5Tw1Jlk4pe0"},"source":["A toy model"]},{"cell_type":"code","metadata":{"id":"dWO1QfaT4pEj"},"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n","  tf.keras.layers.Dense(128,activation='relu'),\n","  tf.keras.layers.Dense(10, activation='softmax')\n","])\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZORKxPm4xP4"},"source":["Create a TensorBoard callback to capture performance profiles and call it while training the model"]},{"cell_type":"code","metadata":{"id":"SWcdaFly4wyv"},"source":["# Create a TensorBoard callback\n","logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n","                                                 histogram_freq = 1,\n","                                                 profile_batch = '500,520')\n","\n","model.fit(ds_train,\n","          epochs=2,\n","          validation_data=ds_test,\n","          callbacks = [tboard_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sm-ayiIz49Qp"},"source":["Usually we don't need too many epochs, in fact we should think of this in the unit of \"iteration\". For example, the above MNIST model has 469 iterations per epoch. Each iteration usually goes through the same computation graph, given there is no special communication or conditional handling etc. in your training loop. In such special cases, consider create special input or dedicate profiling sessions to those conditional scenarios."]},{"cell_type":"markdown","metadata":{"id":"kF4_EXss6K0P"},"source":["## Use the TensorFlow Profiler to profile model training performance\n","\n","The TensorFlow Profiler is embedded within TensorBoard. Load TensorBoard using Colab magic and launch it. View the performance profiles by navigating to the **Profile** tab."]},{"cell_type":"code","metadata":{"id":"BUN-sbWu6liO"},"source":["!kill 1734\n","# Load the TensorBoard notebook extension.\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ELcURlx96pQM"},"source":["# Launch TensorBoard and navigate to the Profile tab to view performance profile\n","%tensorboard --logdir=logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DF93DyB87sAz"},"source":["The **Profile** tab opens the Overview page which shows you a high-level summary of your model performance. Looking at the Step-time Graph on the right, you can see that the model is highly input bound (i.e., it spends a lot of time in the data input piepline). The Overview page also gives you recommendations on potential next steps you can follow to optimize your model performance.\n","\n","To understand where the performance bottleneck occurs in the input pipeline, select the **Trace Viewer** from the **Tools** dropdown on the left. The Trace Viewer shows you a timeline of the different events that occured on the CPU and the GPU during the profiling period.\n","\n","The Trace Viewer shows multiple event groups on the vertical axis. Each event group has multiple horizontal tracks, filled with trace events. The track is an event timeline for events executed on a thread or a GPU stream. Individual events are the colored, rectangular blocks on the timeline tracks. Time moves from left to right. Navigate the trace events by using the keyboard shortcuts `W` (zoom in), `S` (zoom out), `A` (scroll left), and `D` (scroll right).\n","\n","A single rectangle represents a trace event. Select the mouse cursor icon in the floating tool bar (or use the keyboard shortcut `1`) and click the trace event to analyze it. This will display information about the event, such as its start time and duration.\n","\n","In addition to clicking, you can drag the mouse to select a group of trace events. This will give you a list of all the events in that area along with an event summary. Use the `M` key to measure the time duration of the selected events.\n","\n","Trace events are collected from:\n","\n","- **CPU**: CPU events are displayed under an event group named `/host:CPU`. Each track represents a thread on CPU. CPU events include input pipeline events, GPU operation (op) scheduling events, CPU op execution events etc.\n","\n","- **GPU**: GPU events are displayed under event groups prefixed by `/device:GPU:`. Each event group represents one stream on the GPU."]},{"cell_type":"markdown","metadata":{"id":"9VEjIwHO8Tv9"},"source":["## [IMPORTANT!] Debugging and Optimization\n","\n","Study these three posts and you will be using techniques introduced there to profile our transformer model.\n","\n","https://www.tensorflow.org/guide/profiler\n","\n","https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#debug_performance_bottlenecks\n","\n","https://www.tensorflow.org/guide/data_performance"]},{"cell_type":"markdown","metadata":{"id":"_fUnb_oa9SYD"},"source":["# ES-EN NMT Transformer\n","> Talk is cheap, show me the code \\\n","> -- Linus Torvalds\n","\n","The paragraphs introducing transformer and its building blocks are dropped for your workplace cleanness :)"]},{"cell_type":"markdown","metadata":{"id":"fN7pJARIt9uK"},"source":["## Loading the libraries"]},{"cell_type":"code","metadata":{"id":"ZbcvtPlp3YWu"},"source":["import math\n","import os\n","import gc\n","import time\n","import re\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","from google.colab import drive\n","try:\n","    %tensorflow_version 2.x\n","except:\n","    pass\n","import tensorflow as tf\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","import tensorflow_datasets as tfds\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bqyCyv2b5iif"},"source":["Setting some parameters and hyperparameters for our model"]},{"cell_type":"code","metadata":{"id":"rTr3QS6_5tBO"},"source":["# Parameters for our model\n","INPUT_COLUMN = 'input'\n","TARGET_COLUMN = 'target'\n","NUM_SAMPLES = 80000 #40000\n","MAX_VOCAB_SIZE = 2**14\n","\n","BATCH_SIZE = 64  # Batch size for training.\n","EPOCHS = 10  # Number of epochs to train for.\n","MAX_LENGTH = 15\n","\n","# Global parameters\n","root_folder='/content/drive'\n","data_folder_name='MyDrive/Deep Learning System/assignment-5/datasets/eng_spa_translations'\n","checkpoint_folder = \"MyDrive/Deep Learning System/assignment-5/ckpt/\"\n","train_filename='spa.txt'\n","\n","# Variable for data directory\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","checkpoint_path = os.path.abspath(os.path.join(root_folder, checkpoint_folder))\n","\n","# Both train and test set are in the root data directory\n","train_path = DATA_PATH\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dCD9jwXsLwS_"},"source":["Mount our Google Drive unit to access the datafiles from the notebook"]},{"cell_type":"code","metadata":{"id":"eQpbl1pXCR0p"},"source":["drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpKxZHcDVFyp"},"source":["# DATA_PATH is set in the above, get the raw string version in case of space presenting\n","DATA_PATH_RAW = DATA_PATH.replace(' ', '\\ ')\n","\n","# download spanish-english dataset\n","url = \"http://www.manythings.org/anki/spa-eng.zip\"\n","!wget -nc {url} -P {DATA_PATH_RAW}\n","FILE_EXTRACTED = f\"{DATA_PATH_RAW}/spa.txt\"\n","![ ! -f {FILE_EXTRACTED} ] && unzip {DATA_PATH_RAW}/*.zip -d {DATA_PATH_RAW}\n","\n","# download the nonbreaking-prefixes\n","url_en = \"https://raw.githubusercontent.com/moses-smt/mosesdecoder/master/scripts/share/nonbreaking_prefixes/nonbreaking_prefix.en\"\n","url_es = \"https://raw.githubusercontent.com/moses-smt/mosesdecoder/master/scripts/share/nonbreaking_prefixes/nonbreaking_prefix.es\"\n","!wget -nc {url_en} -P {DATA_PATH_RAW}\n","!wget -nc {url_es} -P {DATA_PATH_RAW}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnomPENWc3gD"},"source":["def preprocess_text_nonbreaking(corpus, non_breaking_prefixes):\n","  corpus_cleaned = corpus\n","  # Add the string $$$ before the non breaking prefixes\n","  # To avoid remove dots from some words\n","  for prefix in non_breaking_prefixes:\n","    corpus_cleaned = corpus_cleaned.replace(prefix, prefix + '$$$')\n","  # Remove dots not at the end of a sentence\n","  corpus_cleaned = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_cleaned)\n","  # Remove the $$$ mark\n","  corpus_cleaned = re.sub(r\"\\.\\$\\$\\$\", '', corpus_cleaned)\n","  # Rmove multiple white spaces\n","  corpus_cleaned = re.sub(r\"  +\", \" \", corpus_cleaned)\n","\n","  return corpus_cleaned\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPlOT-2mlw0r"},"source":["## Loading the dataset"]},{"cell_type":"markdown","metadata":{"id":"7Bf2mfHHbqGK"},"source":["Loading the list of non breaking prefixes for the english and the spanish sentences"]},{"cell_type":"code","metadata":{"id":"fjKW8DnObtvl"},"source":["with open(DATA_PATH+\"/nonbreaking_prefix.en\", \n","          mode = \"r\", encoding = \"utf-8\") as f:\n","    non_breaking_prefix_en = f.read()\n","with open(DATA_PATH+\"/nonbreaking_prefix.es\", \n","          mode = \"r\", encoding = \"utf-8\") as f:\n","    non_breaking_prefix_es = f.read()\n","\n","non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n","non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]\n","non_breaking_prefix_es = non_breaking_prefix_es.split(\"\\n\")\n","non_breaking_prefix_es = [' ' + pref + '.' for pref in non_breaking_prefix_es]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gdgqJNZc63nk"},"source":["Load the dataset into a pandas dataframe and apply the preprocess function to the input and target columns."]},{"cell_type":"code","metadata":{"id":"0G8Wa9FBdy5Y"},"source":["# Load the dataset: sentence in english, sentence in spanish \n","df=pd.read_csv(train_filenamepath, sep=\"\\t\", header=None, names=[INPUT_COLUMN,TARGET_COLUMN], usecols=[0,1], \n","               nrows=NUM_SAMPLES)\n","# Preprocess the input data\n","input_data=df[INPUT_COLUMN].apply(lambda x : preprocess_text_nonbreaking(x, non_breaking_prefix_en)).tolist()\n","# Preprocess and include the end of sentence token to the target text\n","target_data=df[TARGET_COLUMN].apply(lambda x : preprocess_text_nonbreaking(x, non_breaking_prefix_es)).tolist()\n","\n","print('Number of sentences: ',len(input_data))\n","print(input_data[:5])\n","print(target_data[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMAFFdpIyNZd"},"source":["#Delete the dataframe and release the memory (if it is possible)\n","del df\n","gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEFw0D2vP_Dl"},"source":["## Tokenize the text data\n"]},{"cell_type":"code","metadata":{"id":"khsaxokjofHr"},"source":["def subword_tokenize(corpus, vocab_size, max_length):\n","  # Create the vocabulary using Subword tokenization\n","  tokenizer_corpus = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    corpus, target_vocab_size=vocab_size)\n","  # Get the final vocab size, adding the eos and sos tokens\n","  num_words = tokenizer_corpus.vocab_size + 2\n","  # Set eos and sos token\n","  sos_token = [num_words-2]\n","  eos_token = [num_words-1]\n","  # Tokenize the corpus\n","  sentences = [sos_token + tokenizer_corpus.encode(sentence) + eos_token\n","          for sentence in corpus]\n","  # Identify the index of the sentences longer than max length\n","  idx_to_remove = [count for count, sent in enumerate(sentences)\n","                 if len(sent) > max_length]\n","  #Pad the sentences\n","  sentences = tf.keras.preprocessing.sequence.pad_sequences(sentences,\n","                                                       value=0,\n","                                                       padding='post',\n","                                                       maxlen=max_length)\n","  \n","  return sentences, tokenizer_corpus, num_words, sos_token, eos_token, idx_to_remove\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"onrwROJrquij"},"source":["# Tokenize and pad the input sequences\n","encoder_inputs, tokenizer_inputs, num_words_inputs, sos_token_input, eos_token_input, del_idx_inputs= subword_tokenize(input_data, \n","                                                                                                        MAX_VOCAB_SIZE, MAX_LENGTH)\n","# Tokenize and pad the outputs sequences\n","decoder_outputs, tokenizer_outputs, num_words_output, sos_token_output, eos_token_output, del_idx_outputs = subword_tokenize(target_data, \n","                                                                                                        MAX_VOCAB_SIZE, MAX_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VF4l2stYEu2l"},"source":["print('Size of Input Vocabulary: ', num_words_inputs)\n","print('Size of Output Vocabulary: ', num_words_output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ypm8h5aZQTZ1"},"source":["## Create the batch data generator"]},{"cell_type":"markdown","metadata":{"id":"9FP0WPsdM8hl"},"source":["- Create a batch data generator: we want to train the model on batches, group of sentences, so we need to create a Dataset using the tf.data library and the function batch_on_slices on the input and output sequences."]},{"cell_type":"code","metadata":{"id":"wFxMp3TOIYff"},"source":["# Define a dataset \n","dataset = tf.data.Dataset.from_tensor_slices(\n","    (encoder_inputs, decoder_outputs))\n","dataset = dataset.shuffle(len(input_data), reshuffle_each_iteration=True).batch(\n","    BATCH_SIZE, drop_remainder=True)\n","\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ycT0YqydRcUd"},"source":["## Building Blocks for Transformer"]},{"cell_type":"code","metadata":{"id":"2rEoCNJURbrT"},"source":["def scaled_dot_product_attention(queries, keys, values, mask):\n","    # Calculate the dot product, QK_transpose\n","    product = tf.matmul(queries, keys, transpose_b=True)\n","    # Get the scale factor\n","    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n","    # Apply the scale factor to the dot product\n","    scaled_product = product / tf.math.sqrt(keys_dim)\n","    # Apply masking when it is requiered\n","    if mask is not None:\n","        scaled_product += (mask * -1e9)\n","    # dot product with Values\n","    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n","    \n","    return attention"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvq4I9uTX5p7"},"source":["class MultiHeadAttention(layers.Layer):\n","    \n","    def __init__(self, n_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.n_heads = n_heads\n","        \n","    def build(self, input_shape):\n","        self.d_model = input_shape[-1]\n","        assert self.d_model % self.n_heads == 0\n","        # Calculate the dimension of every head or projection\n","        self.d_head = self.d_model // self.n_heads\n","        # Set the weight matrices for Q, K and V\n","        self.query_lin = layers.Dense(units=self.d_model)\n","        self.key_lin = layers.Dense(units=self.d_model)\n","        self.value_lin = layers.Dense(units=self.d_model)\n","        # Set the weight matrix for the output of the multi-head attention W0\n","        self.final_lin = layers.Dense(units=self.d_model)\n","        \n","    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n","        # Set the dimension of the projections\n","        shape = (batch_size,\n","                 -1,\n","                 self.n_heads,\n","                 self.d_head)\n","        # Split the input vectors\n","        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n","        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_length, d_proj)\n","    \n","    def call(self, queries, keys, values, mask):\n","        # Get the batch size\n","        batch_size = tf.shape(queries)[0]\n","        # Set the Query, Key and Value matrices\n","        queries = self.query_lin(queries)\n","        keys = self.key_lin(keys)\n","        values = self.value_lin(values)\n","        # Split Q, K y V between the heads or projections\n","        queries = self.split_proj(queries, batch_size)\n","        keys = self.split_proj(keys, batch_size)\n","        values = self.split_proj(values, batch_size)\n","        # Apply the scaled dot product\n","        attention = scaled_dot_product_attention(queries, keys, values, mask)\n","        # Get the attention scores\n","        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n","        # Concat the h heads or projections\n","        concat_attention = tf.reshape(attention,\n","                                      shape=(batch_size, -1, self.d_model))\n","        # Apply W0 to get the output of the multi-head attention\n","        outputs = self.final_lin(concat_attention)\n","        \n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2wc6sYlX0dr"},"source":["class PositionalEncoding(layers.Layer):\n","\n","    def __init__(self):\n","        super(PositionalEncoding, self).__init__()\n","    \n","    def get_angles(self, pos, i, d_model): # pos: (seq_length, 1) i: (1, d_model)\n","        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n","        return pos * angles # (seq_length, d_model)\n","\n","    def call(self, inputs):\n","        # input shape batch_size, seq_length, d_model\n","        seq_length = inputs.shape.as_list()[-2]\n","        d_model = inputs.shape.as_list()[-1]\n","        # Calculate the angles given the input\n","        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n","                                 np.arange(d_model)[np.newaxis, :],\n","                                 d_model)\n","        # Calculate the positional encodings\n","        angles[:, 0::2] = np.sin(angles[:, 0::2])\n","        angles[:, 1::2] = np.cos(angles[:, 1::2])\n","        # Expand the encodings with a new dimension\n","        pos_encoding = angles[np.newaxis, ...]\n","        \n","        return inputs + tf.cast(pos_encoding, tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UV0ZMH7KT_KZ"},"source":["class EncoderLayer(layers.Layer):\n","    \n","    def __init__(self, FFN_units, n_heads, dropout_rate):\n","        super(EncoderLayer, self).__init__()\n","        # Hidden units of the feed forward component\n","        self.FFN_units = FFN_units\n","        # Set the number of projectios or heads\n","        self.n_heads = n_heads\n","        # Dropout rate\n","        self.dropout_rate = dropout_rate\n","    \n","    def build(self, input_shape):\n","        self.d_model = input_shape[-1]\n","        # Build the multihead layer\n","        self.multi_head_attention = MultiHeadAttention(self.n_heads)\n","        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n","        # Layer Normalization\n","        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n","        # Fully connected feed forward layer\n","        self.ffn1_relu = layers.Dense(units=self.FFN_units, activation=\"relu\")\n","        self.ffn2 = layers.Dense(units=self.d_model)\n","        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n","        # Layer normalization\n","        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n","        \n","    def call(self, inputs, mask, training):\n","        # Forward pass of the multi-head attention\n","        attention = self.multi_head_attention(inputs,\n","                                              inputs,\n","                                              inputs,\n","                                              mask)\n","        attention = self.dropout_1(attention, training=training)\n","        # Call to the residual connection and layer normalization\n","        attention = self.norm_1(attention + inputs)\n","        # Call to the FC layer\n","        outputs = self.ffn1_relu(attention)\n","        outputs = self.ffn2(outputs)\n","        outputs = self.dropout_2(outputs, training=training)\n","        # Call to residual connection and the layer normalization\n","        outputs = self.norm_2(outputs + attention)\n","        \n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-P92KeZih60"},"source":["class Encoder(layers.Layer):\n","    \n","    def __init__(self,\n","                 n_layers,\n","                 FFN_units,\n","                 n_heads,\n","                 dropout_rate,\n","                 vocab_size,\n","                 d_model,\n","                 name=\"encoder\"):\n","        super(Encoder, self).__init__(name=name)\n","        self.n_layers = n_layers\n","        self.d_model = d_model\n","        # The embedding layer\n","        self.embedding = layers.Embedding(vocab_size, d_model)\n","        # Positional encoding layer\n","        self.pos_encoding = PositionalEncoding()\n","        self.dropout = layers.Dropout(rate=dropout_rate)\n","        # Stack of n layers of multi-head attention and FC\n","        self.enc_layers = [EncoderLayer(FFN_units,\n","                                        n_heads,\n","                                        dropout_rate) \n","                           for _ in range(n_layers)]\n","    \n","    def call(self, inputs, mask, training):\n","        # Get the embedding vectors\n","        outputs = self.embedding(inputs)\n","        # Scale the embeddings by sqrt of d_model\n","        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        # Positional encodding\n","        outputs = self.pos_encoding(outputs)\n","        outputs = self.dropout(outputs, training)\n","        # Call the stacked layers\n","        for i in range(self.n_layers):\n","            outputs = self.enc_layers[i](outputs, mask, training)\n","\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZWZyFBnwy8u"},"source":["class DecoderLayer(layers.Layer):\n","    \n","    def __init__(self, FFN_units, n_heads, dropout_rate):\n","        super(DecoderLayer, self).__init__()\n","        self.FFN_units = FFN_units\n","        self.n_heads = n_heads\n","        self.dropout_rate = dropout_rate\n","    \n","    def build(self, input_shape):\n","        self.d_model = input_shape[-1]\n","        \n","        # Self multi head attention, causal attention\n","        self.multi_head_causal_attention = MultiHeadAttention(self.n_heads)\n","        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n","        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n","        \n","        # Multi head attention, encoder-decoder attention \n","        self.multi_head_enc_dec_attention = MultiHeadAttention(self.n_heads)\n","        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n","        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n","        \n","        # Feed foward\n","        self.ffn1_relu = layers.Dense(units=self.FFN_units,\n","                                    activation=\"relu\")\n","        self.ffn2 = layers.Dense(units=self.d_model)\n","        self.dropout_3 = layers.Dropout(rate=self.dropout_rate)\n","        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n","        \n","    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n","        # Call the masked causal attention\n","        attention = self.multi_head_causal_attention(inputs,\n","                                                inputs,\n","                                                inputs,\n","                                                mask_1)\n","        attention = self.dropout_1(attention, training)\n","        # Residual connection and layer normalization\n","        attention = self.norm_1(attention + inputs)\n","        # Call the encoder-decoder attention\n","        attention_2 = self.multi_head_enc_dec_attention(attention,\n","                                                  enc_outputs,\n","                                                  enc_outputs,\n","                                                  mask_2)\n","        attention_2 = self.dropout_2(attention_2, training)\n","        # Residual connection and layer normalization\n","        attention_2 = self.norm_2(attention_2 + attention)\n","        # Call the Feed forward\n","        outputs = self.ffn1_relu(attention_2)\n","        outputs = self.ffn2(outputs)\n","        outputs = self.dropout_3(outputs, training)\n","        # Residual connection and layer normalization\n","        outputs = self.norm_3(outputs + attention_2)\n","        \n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpzdiWHiwywF"},"source":["class Decoder(layers.Layer):\n","    \n","    def __init__(self,\n","                 n_layers,\n","                 FFN_units,\n","                 n_heads,\n","                 dropout_rate,\n","                 vocab_size,\n","                 d_model,\n","                 name=\"decoder\"):\n","        super(Decoder, self).__init__(name=name)\n","        self.d_model = d_model\n","        self.n_layers = n_layers\n","        # Embedding layer\n","        self.embedding = layers.Embedding(vocab_size, d_model)\n","        # Positional encoding layer\n","        self.pos_encoding = PositionalEncoding()\n","        self.dropout = layers.Dropout(rate=dropout_rate)\n","        # Stacked layers of multi-head attention and feed forward\n","        self.dec_layers = [DecoderLayer(FFN_units,\n","                                        n_heads,\n","                                        dropout_rate) \n","                           for _ in range(n_layers)]\n","    \n","    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n","        # Get the embedding vectors\n","        outputs = self.embedding(inputs)\n","        # Scale by sqrt of d_model\n","        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        # Positional encodding\n","        outputs = self.pos_encoding(outputs)\n","        outputs = self.dropout(outputs, training)\n","        # Call the stacked layers\n","        for i in range(self.n_layers):\n","            outputs = self.dec_layers[i](outputs,\n","                                         enc_outputs,\n","                                         mask_1,\n","                                         mask_2,\n","                                         training)\n","\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x5sJYkjbz5DD"},"source":["# Transformer [coding needed]\n","\n","Look at this [post](https://keras.io/guides/customizing_what_happens_in_fit/) and figure out how to modify the model to enable `.fit()` method\n","\n","Some changes are made here, pay attention to the `train_step`. It replaces the `main_train`."]},{"cell_type":"code","metadata":{"id":"GqvqNjJPwyh-"},"source":["class Transformer(tf.keras.Model):\n","    \n","    def __init__(self,\n","                 vocab_size_enc,\n","                 vocab_size_dec,\n","                 d_model,\n","                 n_layers,\n","                 FFN_units,\n","                 n_heads,\n","                 dropout_rate,\n","                 name=\"transformer\"):\n","        super(Transformer, self).__init__(name=name)\n","        # Build the encoder\n","        self.encoder = Encoder(n_layers,\n","                               FFN_units,\n","                               n_heads,\n","                               dropout_rate,\n","                               vocab_size_enc,\n","                               d_model)\n","        # Build the decoder\n","        self.decoder = Decoder(n_layers,\n","                               FFN_units,\n","                               n_heads,\n","                               dropout_rate,\n","                               vocab_size_dec,\n","                               d_model)\n","        # build the linear transformation and softmax function\n","        self.last_linear = layers.Dense(units=vocab_size_dec, name=\"lin_ouput\")\n","    \n","    def create_padding_mask(self, seq): #seq: (batch_size, seq_length)\n","        # Create the mask for padding\n","        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","        return mask[:, tf.newaxis, tf.newaxis, :]\n","\n","    def create_look_ahead_mask(self, seq):\n","        # Create the mask for the causal attention\n","        seq_len = tf.shape(seq)[1]\n","        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","        return look_ahead_mask\n","    \n","    # def call(self, enc_inputs, dec_inputs, training):\n","    def call(self, enc_inputs, dec_inputs, training):\n","        # Create the padding mask for the encoder\n","        enc_mask = self.create_padding_mask(enc_inputs)\n","        # Create the mask for the causal attention\n","        dec_mask_1 = tf.maximum(\n","            self.create_padding_mask(dec_inputs),\n","            self.create_look_ahead_mask(dec_inputs)\n","        )\n","        # Create the mask for the encoder-decoder attention\n","        dec_mask_2 = self.create_padding_mask(enc_inputs)\n","        # Call the encoder\n","        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n","        # Call the decoder\n","        dec_outputs = self.decoder(dec_inputs,\n","                                   enc_outputs,\n","                                   dec_mask_1,\n","                                   dec_mask_2,\n","                                   training)\n","        # Call the Linear and Softmax functions\n","        outputs = self.last_linear(dec_outputs)\n","        \n","        return outputs\n","\n","    # `main_train` (below) need to be somehow adopted here\n","    # =========================================================================\n","    \n","    # ======================================================= ref code 11 Lines \n","    # (don't need to match this, just for reference)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AM6zndzkAxC0"},"source":["def loss_function(target, pred):\n","    mask = tf.math.logical_not(tf.math.equal(target, 0))\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n","                                                            reduction=\"none\")\n","    loss_ = loss_object(target, pred)\n","    \n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","    \n","    return tf.reduce_mean(loss_)\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    \n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","        \n","        self.d_model = tf.cast(d_model, tf.float32)\n","        self.warmup_steps = warmup_steps\n","    \n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n","        arg2 = tf.cast(step, tf.float32) * (self.warmup_steps**-1.5)\n","        \n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeIsRsrhOhcn"},"source":["# from tqdm import tqdm\n","\n","# def main_train(dataset, transformer, n_epochs, print_every=50):\n","#   ''' Train the transformer model for n_epochs using the data generator dataset'''\n","#   losses = []\n","#   accuracies = []\n","#   # In every epoch\n","#   for epoch in range(n_epochs):\n","#     print(\"Starting epoch {}\".format(epoch+1))\n","#     start = time.time()\n","#     # Reset the losss and accuracy calculations\n","#     train_loss.reset_states()\n","#     train_accuracy.reset_states()\n","#     # Get a batch of inputs and targets\n","#     for (batch, (enc_inputs, targets)) in enumerate(tqdm(dataset)):\n","#         # Set the decoder inputs\n","#         dec_inputs = targets[:, :-1]\n","#         # Set the target outputs, right shifted\n","#         dec_outputs_real = targets[:, 1:]\n","#         with tf.GradientTape() as tape:\n","#             # Call the transformer and get the predicted output\n","#             predictions = transformer(enc_inputs, dec_inputs, True)\n","#             # Calculate the loss\n","#             loss = loss_function(dec_outputs_real, predictions)\n","#         # Update the weights and optimizer\n","#         gradients = tape.gradient(loss, transformer.trainable_variables)\n","#         optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","#         # Save and store the metrics\n","#         train_loss(loss)\n","#         train_accuracy(dec_outputs_real, predictions)\n","        \n","#         if batch % print_every == 0:\n","#             losses.append(train_loss.result())\n","#             accuracies.append(train_accuracy.result())\n","#             print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n","#                 epoch+1, batch, train_loss.result(), train_accuracy.result()), flush=True)\n","            \n","#     # Checkpoint the model on every epoch        \n","#     ckpt_save_path = ckpt_manager.save()\n","#     print(\"Saving checkpoint for epoch {} in {}\".format(epoch+1,\n","#                                                         ckpt_save_path))\n","#     print(\"Time for 1 epoch: {} secs\\n\".format(time.time() - start))\n","\n","#   return losses, accuracies"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hLqH4ksXJHPu"},"source":["Setting the hyperparameters and parameters of the model and training process:"]},{"cell_type":"code","metadata":{"id":"QGmrQfakTKUV"},"source":["# Set hyperparamters for the model\n","D_MODEL = 512 # 512\n","N_LAYERS = 4 # 6\n","FFN_UNITS = 512 # 2048\n","N_HEADS = 8 # 8\n","DROPOUT_RATE = 0.1 # 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hCk9aUDqaMo"},"source":["Now we define and create all the elements to train the model and evaluate it."]},{"cell_type":"code","metadata":{"id":"qiOdqQ5qPs8z"},"source":["# Clean the session\n","tf.keras.backend.clear_session()\n","# Create the Transformer model\n","transformer = Transformer(vocab_size_enc=num_words_inputs,\n","                          vocab_size_dec=num_words_output,\n","                          d_model=D_MODEL,\n","                          n_layers=N_LAYERS,\n","                          FFN_units=FFN_UNITS,\n","                          n_heads=N_HEADS,\n","                          dropout_rate=DROPOUT_RATE)\n","\n","# Define a metric to store the mean loss of every epoch\n","train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n","# Define a matric to save the accuracy in every epoch\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n","# Create the scheduler for learning rate decay\n","leaning_rate = CustomSchedule(D_MODEL)\n","# Create the Adam optimizer\n","optimizer = tf.keras.optimizers.Adam(leaning_rate,\n","                                     beta_1=0.9,\n","                                     beta_2=0.98,\n","                                     epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2tomccSt_sWh"},"source":["# `Fit` & Profile!"]},{"cell_type":"code","metadata":{"id":"Pp1pnDhpgZDM"},"source":["transformer.compile(optimizer=optimizer, loss=loss_function, metrics=[train_accuracy])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYttrfNVhVMG"},"source":["from datetime import datetime\n","\n","# Create a TensorBoard callback\n","logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n","                                                 histogram_freq = 1,\n","                                                 profile_batch = '500,520')\n","\n","transformer.fit(dataset, epochs=2, callbacks = [tboard_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"we5hYFaRweu2"},"source":["# Load the TensorBoard notebook extension.\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTiFu-fOwYpG"},"source":["# Launch TensorBoard and navigate to the Profile tab to view performance profile\n","%tensorboard --logdir=logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IvukUhQ_Ckmw"},"source":["# Experiments & Write up\n","\n","1. Describe your profiling results on Colab, according to your understanding of this particular transformer architecture design. \n","\n","2. Identify bottlenecks in the training phase using these diagrams. Choose three bottlenecks you think could be improved or eliminated by employing techniques learned from [Debugging and Optimization](https://colab.research.google.com/drive/1MwaOPAW8xfadGhFlsuziLRf80YfGcOnq?authuser=1#scrollTo=9VEjIwHO8Tv9) readings.\n","\n","3. Carry out experiments (on Colab) testing your modifications to the pipeline / model, discuss:\n","- Why do you think it is an improvable bottleneck?\n","- How do you plan to modify to make it better?\n","- Does your plan work out well? If not, what could be the preventive factor?\n","\n","4. Run the `unimproved version` notebook on ThetaGPU single-gpu queue, report your finding on profiling result difference. Are those bottlenecks you identified still bottlenecks?"]}]}