{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW5-summary.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"H0vtdWBYhW_E"},"source":["> In assignment 3, we used a vanilla transformer for Spanish-English Neural Machine Translation. It took quite a long time to train (compared to those smaller models), so we will learn to use a profiler to identify what exactly is the bottlenecks and possible improvements.\n",">\n","> The first part is a quick demo on how to use the TensorFlow Profiler. A couple of post readings will guide you towards different profiler use cases. Then you need to complete the modification to the `Transformer` Class in order to use `.fit()` method. This is required for profiler callbacks during training. After profiling the vanilla transformer, you will describe your profiling results to identify bottlenecks, propose and experiment to reduce or eliminate 3 of these bottlenecks. Discuss your experiment and results. Finally, rerun the non-improved version on ThetaGPU and compare profiling differences, and answer some questions. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"AWGTq33B8ovZ"},"source":["# Experiments & Write up\n","\n","1. Describe your profiling results on Colab, according to your understanding of this particular transformer architecture design. \n","\n","2. Identify bottlenecks in the training phase using these diagrams. Choose three bottlenecks you think could be improved or eliminated by employing techniques learned from [Debugging and Optimization](https://colab.research.google.com/drive/1MwaOPAW8xfadGhFlsuziLRf80YfGcOnq?authuser=1#scrollTo=9VEjIwHO8Tv9) readings.\n","\n","3. Carry out experiments (on Colab) testing your modifications to the pipeline / model, discuss:\n","- Why do you think it is an improvable bottleneck?\n","- How do you plan to modify to make it better?\n","- Does your plan work out well? If not, what could be the preventive factor?\n","\n","4. Run the `unimproved version` notebook on ThetaGPU single-gpu queue, report your finding on profiling result difference. Are those bottlenecks you identified still bottlenecks?"]},{"cell_type":"markdown","metadata":{"id":"AU4zpdGoAMyE"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"lKImH_1CZ7I0","executionInfo":{"status":"ok","timestamp":1635978570797,"user_tz":300,"elapsed":4337,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["%%capture\n","!pip install -U tensorboard-plugin-profile"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1ko20uqLNIm","executionInfo":{"status":"ok","timestamp":1635980426722,"user_tz":300,"elapsed":167,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"59dd8ca3-c842-4d85-ef4d-d38c117acb7f"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd \"/content/drive/MyDrive/Courses/Fall 2021/dlsys/DeepLearningSystems-Fall2021/HW5\""],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Courses/Fall 2021/dlsys/DeepLearningSystems-Fall2021/HW5\n"]}]},{"cell_type":"markdown","metadata":{"id":"Mo4ugEIsGLhn"},"source":["# Data preparations\n","\n","See see the [data-setup.ipynb](https://github.com/tuanpham96/DeepLearningSystems-Fall2021/tree/main/HW5/notebooks/data-setup.ipynb) notebook"]},{"cell_type":"markdown","metadata":{"id":"YiDvU-K7F322"},"source":["# ThetaGPU\n","See the [HW5-thetagpu.ipynb](https://github.com/tuanpham96/DeepLearningSystems-Fall2021/tree/main/HW5/notebooks/HW5-thetagpu.ipynb) notebook"]},{"cell_type":"markdown","metadata":{"id":"zfVNwDYAATbv"},"source":["# Colab"]},{"cell_type":"markdown","metadata":{"id":"ykWhozVWAXKK"},"source":["## Essentials"]},{"cell_type":"code","metadata":{"id":"HSe4Fr7TTE77","executionInfo":{"status":"ok","timestamp":1635980429168,"user_tz":300,"elapsed":2356,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["from datetime import datetime\n","from src.routines import *"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRPEJ-XFLxD0","executionInfo":{"status":"ok","timestamp":1635980429169,"user_tz":300,"elapsed":16,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["# Define paths\n","DATA_PATH = 'data/eng_spa_translations'\n","OUTPUT_PATH = 'output'\n","TRAIN_FILENAME = 'spa.txt'\n","URL_NONBREAKING_FILES = ['nonbreaking_prefix.en', 'nonbreaking_prefix.es']"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyYDaXj6Spj9","executionInfo":{"status":"ok","timestamp":1635980429170,"user_tz":300,"elapsed":15,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["# Define configs\n","data_files = configure_datafiles(\n","    data_path               = DATA_PATH, \n","    train_filename          = TRAIN_FILENAME, \n","    nonbreaking_filenames   = URL_NONBREAKING_FILES\n",")\n","\n","model_config = dict(    \n","    d_model                 = 512,\n","    n_layers                = 4,\n","    FFN_units               = 512,\n","    n_heads                 = 8,\n","    dropout_rate            = 0.1,\n","    act_fun                 = 'relu',\n",")\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dEY3qewka2rk"},"source":["## Baseline"]},{"cell_type":"code","metadata":{"id":"b7nLmIAOTrwp","executionInfo":{"status":"ok","timestamp":1635979165478,"user_tz":300,"elapsed":79141,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["# Load and tranform data \n","dataset, token_dset = load_datasets(data_files) \n","\n","# Clean the session\n","tf.keras.backend.clear_session()  "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKcTl9j7a6JO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635979614554,"user_tz":300,"elapsed":449116,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"7c7a9cd4-810f-4a4a-b7fd-1ba53709347e"},"source":["# Model name \n","model_name = 'transformer-ColabBaseline'\n","# Create model\n","transformer = Transformer(\n","    vocab_size_enc=token_dset['input']['num_words'], \n","    vocab_size_dec=token_dset['target']['num_words'],\n","    **model_config\n",")\n","# Compile model \n","compile_model(transformer, model_config)\n","# Fit with callbacks\n","fit_model_with_callbacks(transformer, dataset, model_name, num_epochs=2)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1250/1250 [==============================] - 228s 172ms/step - loss: 2.5786 - train_accuracy: 0.1805\n","Epoch 2/2\n","1250/1250 [==============================] - 210s 168ms/step - loss: 1.5255 - train_accuracy: 0.2731\n"]}]},{"cell_type":"markdown","metadata":{"id":"3oYZ43p1at9k"},"source":["## Try 1: Set `TF_GPU_THREAD_MODE=gpu_private` and use `cache` for data\n"]},{"cell_type":"code","metadata":{"id":"USOjHLhWdPCM","executionInfo":{"status":"ok","timestamp":1635980546853,"user_tz":300,"elapsed":76537,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private' # Change flag \n","dataset, token_dset = load_datasets(data_files, use_cache=True) # Use flag \n","tf.keras.backend.clear_session()  "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8Hxx0dua_vr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635980130541,"user_tz":300,"elapsed":442527,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"e17c51e4-ac00-434f-cbda-e8d607a969f4"},"source":["# Model name \n","model_name = 'transformer-ColabFlagNCache'\n","# Create model\n","transformer = Transformer(\n","    vocab_size_enc=token_dset['input']['num_words'], \n","    vocab_size_dec=token_dset['target']['num_words'],\n","    **model_config\n",")\n","# Compile model \n","compile_model(transformer, model_config)\n","# Fit with callbacks\n","fit_model_with_callbacks(transformer, dataset, model_name, num_epochs=2)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1250/1250 [==============================] - 223s 171ms/step - loss: 2.5767 - train_accuracy: 0.1805\n","Epoch 2/2\n","1250/1250 [==============================] - 209s 167ms/step - loss: 1.5351 - train_accuracy: 0.2717\n"]}]},{"cell_type":"markdown","metadata":{"id":"PWYLLBStZD4u"},"source":["## Try 2: Minimize `cast` ops"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DA26MXEKwKF5","executionInfo":{"status":"ok","timestamp":1635980547330,"user_tz":300,"elapsed":158,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"4bcf024c-acc3-477a-bed4-fb9fff58b465"},"source":["# this is just one example where trying to replace `cast` op achieves some speedup\n","a = tf.random.normal([10000,100])\n","%timeit -n 100 tf.cast(tf.math.equal(a, 0), tf.float32)\n","%timeit -n 100 tf.where(tf.math.equal(a, 0), 1.0, 0.0)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["100 loops, best of 5: 127 µs per loop\n","100 loops, best of 5: 87.3 µs per loop\n"]}]},{"cell_type":"code","metadata":{"id":"1z_DFK3e_6H4","executionInfo":{"status":"ok","timestamp":1635980577813,"user_tz":300,"elapsed":308,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["from src.model_mincast import *"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVORRGZt__CT","executionInfo":{"status":"ok","timestamp":1635981196613,"user_tz":300,"elapsed":490722,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"a66ec9f1-b071-4e59-dfc4-21903f6fbf22"},"source":["# Model name \n","model_name = 'transformer-ColabMinCast'\n","# Create model\n","transformer = Transformer(\n","    vocab_size_enc=token_dset['input']['num_words'], \n","    vocab_size_dec=token_dset['target']['num_words'],\n","    **model_config\n",")\n","# Compile model \n","compile_model(transformer, model_config)\n","# Fit with callbacks\n","fit_model_with_callbacks(transformer, dataset, model_name, num_epochs=2)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1250/1250 [==============================] - 228s 173ms/step - loss: 2.5716 - train_accuracy: 0.1809\n","Epoch 2/2\n","1250/1250 [==============================] - 213s 170ms/step - loss: 1.5422 - train_accuracy: 0.2703\n"]}]},{"cell_type":"markdown","metadata":{"id":"7kEF6ism-gcQ"},"source":["## Try 3: Turn on `XLA` flags"]},{"cell_type":"code","metadata":{"id":"ya10yBqmo8qF","executionInfo":{"status":"ok","timestamp":1635981241051,"user_tz":300,"elapsed":79,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["os.environ['TF_XLA_FLAGS']='--tf_xla_auto_jit=2'"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOmeHUz9FGTZ","executionInfo":{"status":"ok","timestamp":1635981242471,"user_tz":300,"elapsed":101,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["# reload the baseline model definitions instead of the mincast version\n","from src.model import * "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"it6CSO8UD1n2","executionInfo":{"status":"ok","timestamp":1635981276911,"user_tz":300,"elapsed":96,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["del scaled_dot_product_attention"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"UiRNR8w3D0wO","executionInfo":{"status":"ok","timestamp":1635981278040,"user_tz":300,"elapsed":91,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["@tf.function(jit_compile=True)\n","def scaled_dot_product_attention(queries, keys, values, mask):\n","    product = tf.matmul(queries, keys, transpose_b=True)\n","    scaled_product = product / tf.math.sqrt(tf.cast(tf.shape(keys)[-1], tf.float32))\n","    scaled_product += (mask * -1e9)\n","    return tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgkPWkTNDvui","executionInfo":{"status":"ok","timestamp":1635981744372,"user_tz":300,"elapsed":454875,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"e6e0e272-434f-4b94-a1d6-bc4d4b72b84f"},"source":["# Model name \n","model_name = 'transformer-ColabXLA'\n","# Create model\n","transformer = Transformer(\n","    vocab_size_enc=token_dset['input']['num_words'], \n","    vocab_size_dec=token_dset['target']['num_words'],\n","    **model_config\n",")\n","# Compile model \n","compile_model(transformer, model_config)\n","# Fit with callbacks\n","fit_model_with_callbacks(transformer, dataset, model_name, num_epochs=2)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1250/1250 [==============================] - 231s 175ms/step - loss: 2.5767 - train_accuracy: 0.1808\n","Epoch 2/2\n","1250/1250 [==============================] - 214s 171ms/step - loss: 1.5201 - train_accuracy: 0.2745\n"]}]},{"cell_type":"markdown","metadata":{"id":"dbWFcEDqlNLE"},"source":["# Tensorboard"]},{"cell_type":"code","metadata":{"id":"p7G1ki8fTMPZ","executionInfo":{"status":"ok","timestamp":1635978538442,"user_tz":300,"elapsed":151,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["# Load the TensorBoard notebook extension.\n","%load_ext tensorboard"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLo6p0D_c2yr"},"source":["# If needed to kill and reload\n","!ps aux | grep '[/]bin/tensorboard' | awk '{print $2}' | xargs kill\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEx50PU4TNSN"},"source":["# Launch TensorBoard and navigate to the Profile tab to view performance profile\n","%tensorboard --logdir=logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WqefBjx1SisI"},"source":[""],"execution_count":null,"outputs":[]}]}